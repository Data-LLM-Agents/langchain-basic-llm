{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial de Cadena Básica de LangChain\n",
                "## Juan Pablo Nieto Cortes\n",
                "\n",
                "Este notebook explica cómo crear tu primera aplicación de procesamiendo de lenguaje natural usando LangChain y Groq (alternativa gratuita a OpenAI)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Instalación de Dependencias"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install langchain-groq python-dotenv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Configuración e Inicialización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain_groq import ChatGroq\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# Inicializar LLM\n",
                "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\")\n",
                "\n",
                "# Crear Prompt\n",
                "prompt = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", \"Eres un mentor experto en tecnología.\"),\n",
                "    (\"user\", \"{input}\")\n",
                "])\n",
                "\n",
                "# Crear Cadena\n",
                "chain = prompt | llm | StrOutputParser()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Demostraciones de Uso\n",
                "A continuación, presentamos varias pruebas para ver cómo responde el modelo a diferentes prompts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pruebas = [\n",
                "    \"¿Qué es LangChain?\",\n",
                "    \"Dame un ejemplo de código en Python para saludar al mundo.\",\n",
                "    \"¿Cuál es la diferencia entre un LLM y una IA tradicional?\",\n",
                "    \"¿Cómo puedo empezar a aprender sobre arquitectura de servidores?\"\n",
                "]\n",
                "\n",
                "for p in pruebas:\n",
                "    print(f\"\\n>>> Usuario: {p}\")\n",
                "    print(f\">>> Mentor: {chain.invoke({'input': p})}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Conclusión\n",
                "Con unas pocas líneas de código, hemos configurado un asistente inteligente capaz de procesar lenguaje natural de forma eficiente y gratuita."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "**Guía creada por Juan Pablo Nieto Cortes** para el laboratorio de AREP."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}